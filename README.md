# Week-15-Lecture
Week-15-Lecture

### AI는 어떻게 ‘글만 보고’ 이미지를 만들 수 있을까?”
* 논문명: Zero-Shot Text-to-Image  Generation
* AI가 문장만 보고 그림을 자동으로 생성하는 기술 — 이 논문이 그 비밀을 풀어줍니다.
  

### 논문배경 - 왜 이런 연구가 필요했을까?
* 세상의 모든 사물에 일일이 라벨을 붙여 가르치는 건 불가능합니다.
* 그래서 인터넷의 방대한 데이터를 가공 없이 학습할 방법이 필요했습니다.
* 배운 적 없는 '새로운 개념'도 스스로 추론해 그려내기 위해서입니다.
* "아코디언 기린" 같은 인간의 엉뚱한 상상력을 현실화하기 위함입니다.
* 복잡한 설정 없이, 사람의 말(자연어)을 바로 이해하도록 만들기 위해서입니다.
* 특정 전문가뿐 아니라 누구나 쉽게 쓸 수 있는 범용 도구가 필요했습니다.
* 결국 AI가 단순한 '모방'을 넘어 진정한 '창작'을 하도록 만들기 위함입니다.

### 기존 연구의 한계점
* GAN과 VAE 기반 모델의 한계
  * 기존 모델은 미리 배운 특정 주제만 그릴 수 있었습니다.(예:얼굴만 잘 그리는 모델, 꽃만 그리는 모델)
  * 구조가 복잡해서 학습시키기가 매우 까다롭고 불안정했습니다.
  * 만들어낸 이미지가 흐릿하거나 똑같은 그림만 반복하곤 했습니다.
  * 사람의 긴 설명이나 복잡한 문장은 제대로 이해하지 못했습니다.
  * 배우지 않은 새로운 것을 그려달라고 하면 전혀 대응하지 못했습니다.

### 논문 목표
* 복잡한 특화 기술들을 모두 버리고, 거대한 트랜스포머(Transformer) 하나로 텍스트와 이미지를 통합하여 마치 언어처럼 학습시키는 것입니다.
* 이를 통해 사람이 정답을 알려주지 않아도, 배운 적 없는 낯선 문장까지 스스로 이해하고 그려내는 강력한 범용성(Zero-shot)을 확보하는 것입니다.

### 논문내용(주요 혁신 및 방법론)  
* 이 연구의 가장 큰 혁신은 이미지를 픽셀 단위(Pixel-level)가 아닌, 언어처럼 토큰 단위(Token-level)로 변환하여 처리했다는 점입니다.
  * 토큰 단위 처리: 퍼즐을 ‘블록’ 단위로 만들기
  * 문장 예시: 나는 / 학교에 / 간다.  즉, 의미 단위로 처리
  * 전체를 빨리 이해하기 쉬운 방식
  * 이를 위해 두 단계의 과정을 거칩니다.

* <img width="722" height="383" alt="image" src="https://github.com/user-attachments/assets/263a639c-71fb-4f9e-a54c-6364a8f417da" />

  * 퍼즐 조각 만들기 (1단계): 세상의 모든 사진을 아주 작은 점(픽셀)으로 기억하는 건 너무 힘듭니다. 그래서 AI는 사진을 1,024개의 큼직한 '퍼즐 조각'으로 바꿔서 기억합니다. (예: '눈동자 조각', '나뭇잎 조각')
  * 이야기 이어 쓰기 (2단계): AI에게 "아보카도 의자"라는 글자(텍스트)를 보여줍니다. 그 뒤에 AI는 배운 대로 자연스럽게 이어질 내용을 퍼즐 조각으로 써 내려갑니다.
  * "옛날에 아보카도 의자가 살았는데..."라고 소설을 쓰듯이, 텍스트 뒤에 어울리는 초록색 곡선 조각(이미지)을 하나씩 채워 넣어 완성된 그림을 만듭니다.


 



### 기여도 및 결과
* Transformer는 영→독, 영→불 번역에서 기존 최고 성능 모델을 모두 넘어서는 성과를 기록했습니다.
* 기존 RNN·CNN 기반 모델은 순차 처리 때문에 시간이 오래 걸렸습니다, 하지만 Transformer는 병렬 처리로 학습 시간을 대폭 단축했습니다.
* Transformer는 RNN과 CNN 없이 Attention만으로 언어를 이해하고 생성할 수 있음을 증명했습니다.
* 이 구조는 이후 BERT, GPT, DALL·E 등 모든 생성형 AI의 기본 설계가 되었습니다.

### 감성컴퓨팅과 GAN
* 감성컴퓨팅은 사람의 감정·뉘앙스·태도 같은 비언어적 의미를 이해하는 AI를 목표로 한다.
* 기존 RNN 기반 모델은 문맥의 미세한 변화나 긴 대화 맥락에서의 감정 흐름 파악이 제한적이었다.
* Transformer의 Self-Attention은 문장 전체 단어를 동시에 비교하여 감정의 전환, 강조, 반전 등을 정밀하게 탐지할 수 있게 한다.
* Multi-Head Attention은 감정·주제·대상·의도 등 복수의 의미 층을 동시에 해석하는 데 유리하다.
* 그 결과, Transformer는 감성 분석, 감정 기반 추천, 상담 챗봇, 생성형 대화 등 감성컴퓨팅 핵심 분야의 정확도와 자연스러움을 크게 향상시켰다.
* 요약하면, Transformer는 문장 전체를 바라보며 의미를 분석하는 구조 덕분에, 감정과 뉘앙스처럼 미세한 맥락을 이해해야 하는 감성컴퓨팅에 최적화된 기반 기술이다.

### 참고 파일

* 논문1. Zero-Shot Text-to-Image  Generation

