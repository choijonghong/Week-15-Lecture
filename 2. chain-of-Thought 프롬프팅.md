# **Chain-of-Thought (CoT) 프롬프팅**

## **1\. Chain-of-Thought (CoT)란 무엇인가?**

\*\*Chain-of-Thought (CoT)\*\*는 쉽게 말해 \*\*"AI에게 수학 문제 풀이 과정을 보여주는 것"\*\*과 같습니다.

우리가 학교에서 수학 시험을 볼 때, 답만 딱 적는 게 아니라 풀이 과정을 함께 적으면 선생님이 점수를 더 잘 주시죠? AI도 마찬가지입니다. 어려운 문제를 풀 때 바로 정답만 내놓으라고 하면 자주 틀리지만, **"어떻게 생각해서 이 답이 나왔는지"** 단계별로 설명하게 하면 정답을 맞힐 확률이 훨씬 높아집니다.

이 기법은 AI에게 \*\*생각하는 순서(사슬)\*\*를 예시로 보여주어, 복잡한 문제도 차근차근 풀 수 있게 도와줍니다.

## **2\. 작동 원리: 알고리즘과 수식으로 이해하기**

단순히 "말을 더 시킨다"는 것을 넘어, 수학적으로는 AI가 확률을 계산하는 방식이 완전히 달라집니다.

### **🧮 1\) 기존 방식 (Standard Prompting)**

기존 방식은 질문($x$)을 입력받아 바로 정답($y$)을 찾으려고 합니다. 마치 복잡한 미로의 입구에서 출구로 한 번에 점프하려는 것과 같습니다.

$$P(y | x)$$

* **설명:** 질문($x$)이 주어졌을 때, 정답($y$)이 나올 확률($P$)을 바로 계산합니다.  
* **문제점:** 중간 과정이 없어서 논리적 비약이 발생하기 쉽습니다.

### **🧠 2\) Chain-of-Thought 방식**

CoT는 질문($x$)과 정답($y$) 사이에 \*\*'생각의 과정($c$, Chain of Thought)'\*\*이라는 다리를 놓습니다.

$$P(y, c | x) \= P(y | c, x) \\cdot P(c | x)$$

* **1단계** $P(c | x)$**:** 질문($x$)을 보고 먼저 \*\*생각의 과정($c$)\*\*을 생성합니다.  
* **2단계** $P(y | c, x)$**:** 질문($x$)과 방금 만든 생각($c$)을 모두 고려해서 최종 \*\*정답($y$)\*\*을 도출합니다.  
* **효과:** $x \\to y$로 가는 어려운 길을 $x \\to c \\to y$로 나누어 가기 때문에 훨씬 정확도가 높아집니다.

## **3\. 예시로 보는 차이점**

가장 큰 차이점은 AI에게 보여주는 \*\*'예시(족보)'\*\*에 \*\*'설명'\*\*이 있느냐 없느냐입니다.

### **❌ 기존 방식 (답만 알려줌)**

*선생님이 문제와 답만 달랑 알려주는 상황입니다.*

\[AI에게 보여주는 예시\]  
Q: 로저는 공 5개가 있다. 캔(3개입)을 2개 더 샀다. 총 몇 개인가?  
A: 정답은 11개.  
\[실전 문제\]  
Q: 식당에 사과 23개가 있었다. 20개를 쓰고 6개를 더 샀다. 지금 몇 개인가?  
\[AI의 답변 (오답)\]  
A: 정답은 27개.  
(이유: 23, 20, 6이라는 숫자만 보고 대충 계산해서 틀림)

### **✅ CoT 방식 (푸는 법을 알려줌)**

*선생님이 문제를 푸는 '생각의 흐름'을 보여주는 상황입니다.*

\[AI에게 보여주는 예시\]  
Q: 로저는 공 5개가 있다. 캔(3개입)을 2개 더 샀다. 총 몇 개인가?  
A: 로저는 처음에 5개로 시작했다. 3개짜리 캔 2개는 6개와 같다(3x2). 그래서 5 \+ 6 \= 11이다. 정답은 11개.  
\[실전 문제\]  
Q: 식당에 사과 23개가 있었다. 20개를 쓰고 6개를 더 샀다. 지금 몇 개인가?  
\[AI의 답변 (정답)\]  
A: 처음에 23개가 있었다. 점심에 20개를 썼으니 23 \- 20 \= 3개가 남는다. 그 후 6개를 더 샀으니 3 \+ 6 \= 9개다. 정답은 9개.

## **4\. CoT가 특히 강력한 3가지 상황**

논문에서는 다음 세 가지 상황에서 AI가 천재적으로 변한다고 설명합니다.

### **① 수학 문제 (산술 추론)**

글자로 된 수학 문제(예: 소금물 농도 구하기)에서 효과가 가장 좋습니다.

* **적용:** 계산 식만 쓰는 게 아니라, "먼저 농도를 구하고, 그 다음에 물을 섞자"는 식으로 단계를 서술합니다.  
* **결과:** 구글의 PaLM 모델은 이 방법을 써서 수학 전용 AI보다 더 높은 점수를 받았습니다.

### **② 상식 퀴즈 (상식 추론)**

세상의 배경지식을 연결해야 풀 수 있는 문제들입니다.

* **문제:** "사람들이 북적이는 곳에 가고 싶다면 어디로 가야 할까? (사막 vs 번화가)"  
* **CoT 사고:** "북적이다 \= 사람이 많다. 사막은 사람이 없다. 번화가는 사람이 많다. 그러니까 정답은 번화가다."

### **③ 논리 퍼즐 (기호 추론)**

사람에겐 쉽지만 AI에겐 헷갈리는 규칙 찾기 문제입니다.

* **문제:** "Bill Gates" 이름의 끝글자만 모으면?  
* **CoT 사고:** "Bill의 끝은 l, Gates의 끝은 s. 합치면 ls."

## **5\. 핵심 발견 (Key Findings)**

### **📈 "덩치가 커야 생각도 잘한다"**

이 기술은 모든 AI에게 통하지 않습니다.

* **작은 AI:** 생각하는 과정을 흉내 내다가 오히려 횡설수설하며 틀립니다.  
* **큰 AI:** 모델의 크기가 일정 수준(약 1,000억 개 파라미터)을 넘어서면, 갑자기 이 능력이 생겨납니다(Emergent Ability). 똑똑한 학생일수록 서술형 문제에 강한 것과 비슷합니다.

### **🛠️ "새로 공부할 필요 없다"**

AI를 다시 훈련시키려면 엄청난 비용이 듭니다. 하지만 CoT는 훈련 없이, \*\*"질문하는 방법(프롬프트)"\*\*만 바꿔서 똑똑하게 만드는 가성비 최고의 기술입니다.

### **🔍 "틀린 이유를 알 수 있다"**

AI가 그냥 틀린 답을 내놓으면 답답합니다. 하지만 CoT를 쓰면 AI가 \*\*"23 \- 20 \= 4"\*\*라고 계산 실수한 과정이 눈에 보입니다. 어디서 틀렸는지 알 수 있으니 고치기도 쉽습니다.

## **6\. 결론**

\*\*Chain-of-Thought(CoT)\*\*는 AI에게 \*\*"생각의 지도"\*\*를 쥐여주는 기술입니다. 어려운 문제를 한 번에 풀려고 하지 말고, 작은 단계로 쪼개서 생각하도록 유도하면 AI의 숨겨진 지능을 200% 활용할 수 있습니다.
