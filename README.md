# Week-15-Lecture
Week-15-Lecture

### AI는 어떻게 ‘글만 보고’ 이미지를 만들 수 있을까?”
* 논문명: Zero-Shot Text-to-Image  Generation
* AI가 문장만 보고 그림을 자동으로 생성하는 기술 — 이 논문이 그 비밀을 풀어줍니다.
  

### 논문배경 - 왜 이런 연구가 필요했을까?
* 세상의 모든 사물에 일일이 라벨을 붙여 가르치는 건 불가능합니다.
* 그래서 인터넷의 방대한 데이터를 가공 없이 학습할 방법이 필요했습니다.
* 배운 적 없는 '새로운 개념'도 스스로 추론해 그려내기 위해서입니다.
* "아코디언 기린" 같은 인간의 엉뚱한 상상력을 현실화하기 위함입니다.
* 복잡한 설정 없이, 사람의 말(자연어)을 바로 이해하도록 만들기 위해서입니다.
* 특정 전문가뿐 아니라 누구나 쉽게 쓸 수 있는 범용 도구가 필요했습니다.
* 결국 AI가 단순한 '모방'을 넘어 진정한 '창작'을 하도록 만들기 위함입니다.

### 기존 연구의 한계점
* GAN과 VAE 기반 모델의 한계
  * 기존 모델은 미리 배운 특정 주제만 그릴 수 있었습니다.(예:얼굴만 잘 그리는 모델, 꽃만 그리는 모델)
  * 구조가 복잡해서 학습시키기가 매우 까다롭고 불안정했습니다.
  * 만들어낸 이미지가 흐릿하거나 똑같은 그림만 반복하곤 했습니다.
  * 사람의 긴 설명이나 복잡한 문장은 제대로 이해하지 못했습니다.
  * 배우지 않은 새로운 것을 그려달라고 하면 전혀 대응하지 못했습니다.

### 논문 목표
* 복잡한 특화 기술들을 모두 버리고, 거대한 트랜스포머(Transformer) 하나로 텍스트와 이미지를 통합하여 마치 언어처럼 학습시키는 것입니다.
* 이를 통해 사람이 정답을 알려주지 않아도, 배운 적 없는 낯선 문장까지 스스로 이해하고 그려내는 강력한 범용성(Zero-shot)을 확보하는 것입니다.

### 논문내용(주요 혁신 및 방법론)  
* 이 연구의 가장 큰 혁신은 이미지를 픽셀 단위(Pixel-level)가 아닌, 언어처럼 토큰 단위(Token-level)로 변환하여 처리했다는 점입니다.
  * 토큰 단위 처리: 퍼즐을 ‘블록’ 단위로 만들기
  * 문장 예시: 나는 / 학교에 / 간다.  즉, 의미 단위로 처리
  * 전체를 빨리 이해하기 쉬운 방식
  * 이를 위해 두 단계의 과정을 거칩니다.

* <img width="722" height="383" alt="image" src="https://github.com/user-attachments/assets/263a639c-71fb-4f9e-a54c-6364a8f417da" />

  * 퍼즐 조각 만들기 (1단계): 세상의 모든 사진을 아주 작은 점(픽셀)으로 기억하는 건 너무 힘듭니다. 그래서 AI는 사진을 1,024개의 큼직한 '퍼즐 조각'으로 바꿔서 기억합니다. (예: '눈동자 조각', '나뭇잎 조각')
  * 이야기 이어 쓰기 (2단계): AI에게 "아보카도 의자"라는 글자(텍스트)를 보여줍니다. 그 뒤에 AI는 배운 대로 자연스럽게 이어질 내용을 퍼즐 조각으로 써 내려갑니다.
  * "옛날에 아보카도 의자가 살았는데..."라고 소설을 쓰듯이, 텍스트 뒤에 어울리는 초록색 곡선 조각(이미지)을 하나씩 채워 넣어 완성된 그림을 만듭니다.

### 기여도 및 결과
* 복잡한 라벨이나 특별 구조 없이 텍스트만으로 이미지 생성에 성공 → 범용 생성형 AI 가능성 제시함.
* Zero-shot 학습으로 처음 보는 문장도 이미지 생성 → 새로운 조합과 상황에 적응함
* 사람 평가에서 기존 GAN 대비 90% 더 현실적, 93% 텍스트와 더 일치 → 품질과 신뢰성 증명
* “아코디언으로 만든 테이퍼”, “크리스마스 스웨터 입은 고슴도치가 개 산책”처럼 추상적 개념 조합 구현 → AI 창의성의 서막
* 이 연구는 ‘글을 읽고 상상해 그리는’ AI 시대를 실질적으로 열어준 첫 사례입니다.

### 감성컴퓨팅과 GAN
* 감성컴퓨팅은 인간의 감정, 분위기, 맥락을 이해하는 AI를 목표로 한다.
* Zero-shot 생성은 배우지 않은 감정 표현도 문장만으로 이해해 이미지로 표현할 수 있게 한다.
* 예를 들어 “슬픈 색감의 겨울 하늘”처럼 감성적 표현 중심 문장도 직접 학습 없이 대응할 수 있다.
* 이는 감정을 숫자 라벨이 아니라 자연어 자체가 가진 맥락으로 해석한다는 의미다.
* 구조나 범주를 미리 정하지 않아 인간 감정의 다층적 표현을 확장할 수 있다.
* 결과적으로 Zero-shot 생성은 감성을 ‘분류’에서 ‘표현’으로 확장하는 감성컴퓨팅의 핵심 기반 기술이 된다.

### 참고 파일

* 논문1. Zero-Shot Text-to-Image  Generation

### 참고 영상

* [유튜브 영상해설  Zero-Shot Text-to-Image Generation](https://www.youtube.com/watch?v=jZRSRbOx1uA&t=40s)


